# Real MCP Benchmark

This directory contains a **REAL** benchmark comparison between Native MCP and GoDeMode MCP, using actual Claude API calls and code execution.

## Overview

Unlike the simulated benchmark (demo.go, demo-fs.go), this benchmark:
- âœ… Makes real Claude API calls
- âœ… Uses actual MCP JSON-RPC protocol
- âœ… Generates and executes real Go code with Yaegi
- âœ… Measures actual latency, tokens, and cost

## Components

### 1. MCP Server (`../real-mcp-server/server.go`)
A real HTTP-based MCP server that implements the MCP JSON-RPC protocol:
- Endpoint: `http://localhost:8080/mcp`
- Tools: add, getCurrentTime, generateUUID, concatenateStrings, reverseString
- Methods: `tools/list`, `tools/call`

### 2. Native MCP Agent (`native_mcp_agent.go`)
Implements the traditional MCP approach:
- Makes sequential Claude API calls
- Each tool call requires a separate API roundtrip
- Claude orchestrates tool usage through conversation

### 3. GoDeMode MCP Agent (`godemode_mcp_agent.go`)
Implements the Code Mode approach:
- Single Claude API call generates Go code
- Code uses the tool registry
- Executes locally with Yaegi interpreter

### 4. Benchmark Runner (`benchmark_runner.go`)
Runs both agents and compares results:
- Starts the MCP server automatically
- Runs both approaches on the same task
- Measures and compares metrics
- Saves results to file

## Prerequisites

1. **Go 1.21+**: For building and running
2. **Anthropic API Key**: Required for Claude API access
3. **Dependencies**: Yaegi interpreter (auto-installed)

## Installation

```bash
# Navigate to this directory
cd /Users/arsheenali/dev/godemode/mcp-benchmark/real-benchmark

# Install dependencies (if needed)
go mod tidy

# Build the benchmark
go build -o real-benchmark benchmark_runner.go native_mcp_agent.go godemode_mcp_agent.go shared_types.go
```

## Running the Benchmark

### Step 1: Set your API key

```bash
export ANTHROPIC_API_KEY=your-api-key-here
```

### Step 2: Run the benchmark

```bash
./real-benchmark
```

The benchmark will:
1. Start the MCP server on port 8080
2. Run the Native MCP agent (makes multiple Claude API calls)
3. Run the GoDeMode MCP agent (makes one Claude API call + executes code)
4. Print comparison results
5. Save results to `../results/real-benchmark-results.txt`

## Expected Output

```
ğŸš€ Starting MCP Server...
â³ Waiting for server to start...
âœ… MCP Server started (PID: 12345)

ğŸ”µ Running Native MCP Benchmark...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Native MCP completed successfully

ğŸŸ¢ Running GoDeMode MCP Benchmark...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… GoDeMode MCP completed successfully

================================================================================
ğŸ“Š REAL MCP BENCHMARK RESULTS
================================================================================

ğŸ“‹ Task:
Complete these 5 utility operations and return the results:
1. Add 10 and 5 together
2. Get the current time
3. Generate a UUID
4. Concatenate ["Hello", "World", "from", "MCP"] with spaces
5. Reverse the string "GoDeMode"

Provide a summary of all results.

ğŸ”µ Native MCP (Sequential Tool Calling)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ… Success
  Total Duration:    8.5s
  API Calls:         7
  Tool Calls:        5
  Input Tokens:      3,245
  Output Tokens:     892
  Total Tokens:      4,137

  Output:
  [Summary from Claude]

ğŸŸ¢ GoDeMode MCP (Code Generation)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ… Success
  Total Duration:      2.1s
  Code Gen Duration:   2.0s
  Execution Duration:  15ms
  API Calls:           1
  Input Tokens:        1,567
  Output Tokens:       324
  Total Tokens:        1,891

  Generated Code:
  [Go code generated by Claude]

  Output:
  [Execution results]

ğŸ“ˆ COMPARISON
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

| Metric              | Native MCP | GoDeMode MCP | Improvement |
|---------------------|------------|--------------|-------------|
| API Calls           | 7          | 1            | 85.7% â†“     |
| Total Duration      | 8.5s       | 2.1s         | 75.3% â†“     |
| Total Tokens        | 4,137      | 1,891        | 54.3% â†“     |
| Tool Calls          | 5          | N/A (in code)| -           |

ğŸ¯ Key Insights:
  â€¢ GoDeMode reduced API calls by 85.7% (7 â†’ 1)
  â€¢ GoDeMode was 75.3% faster (8.5s â†’ 2.1s)
  â€¢ GoDeMode used 54.3% fewer tokens (4,137 â†’ 1,891)

ğŸ’° Cost Estimate (Claude Sonnet pricing):
  â€¢ Native MCP:   $0.023456
  â€¢ GoDeMode MCP: $0.009726
  â€¢ Savings:      58.5% ($0.013730)

================================================================================
```

## Understanding the Results

### Metrics

- **API Calls**: Number of Claude API requests made
- **Total Duration**: End-to-end time including all API calls and execution
- **Code Gen Duration**: Time spent generating code (GoDeMode only)
- **Execution Duration**: Time spent running code locally (GoDeMode only)
- **Input/Output Tokens**: Claude token usage
- **Tool Calls**: Number of MCP tool executions (Native MCP only)

### Cost Calculation

Based on Claude Sonnet pricing (as of 2025):
- Input tokens: $3.00 per 1M tokens
- Output tokens: $15.00 per 1M tokens

Formula:
```
cost = (input_tokens * $3.00 / 1,000,000) + (output_tokens * $15.00 / 1,000,000)
```

## What This Benchmark Measures

### Native MCP Approach
1. Claude analyzes the task
2. Claude decides which tools to use
3. For each tool:
   - Claude makes API call requesting tool use
   - Agent calls MCP server
   - Agent sends result back to Claude
4. Claude summarizes results
5. **Total: ~7-10 API calls**

### GoDeMode MCP Approach
1. Claude receives task + tool descriptions
2. Claude generates complete Go code
3. Code executes locally using Yaegi
4. All tools run without additional API calls
5. **Total: 1 API call**

## Interpreting Results

### When Native MCP May Perform Better
- Very simple tasks (1-2 tools)
- Need step-by-step visibility
- Error recovery is critical
- Tools have high latency (network operations)

### When GoDeMode MCP Performs Better
- Complex workflows (3+ tools)
- Cost optimization is priority
- Performance is critical
- Tools are fast (local operations)
- Same task repeated many times

## Troubleshooting

### "ANTHROPIC_API_KEY environment variable required"
Set your API key:
```bash
export ANTHROPIC_API_KEY=your-key
```

### "Failed to start MCP server"
Check if port 8080 is already in use:
```bash
lsof -i :8080
```

### "Code execution failed"
This may happen if Claude generates invalid code. The benchmark will still show the error and continue.

### API Rate Limits
If you hit rate limits, wait a few minutes and try again.

## Next Steps

1. **Run with different tasks**: Modify the task in `benchmark_runner.go`
2. **Test with more tools**: Add tools to the MCP server
3. **Scale up**: Test with complex multi-step workflows
4. **Compare costs**: Track token usage over many runs

## Related Files

- **Simulated Benchmark**: `../demo.go`, `../demo-fs.go` (educational simulations)
- **Honest Comparison**: `../HONEST_COMPARISON.md` (explains simulation vs real)
- **Integration Guide**: `../INTEGRATION_GUIDE.md` (wrap MCP servers)
- **Main README**: `../README.md` (overview of MCP benchmarks)

---

**This is a REAL benchmark** - it makes actual API calls and measures real performance. Costs and latency will vary based on network conditions, API load, and task complexity.
